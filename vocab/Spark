was
result
caused
array
tasks
being
receive
collect
file
stage
Diagnostics
Thread
Waiting
No
memory
Don't
exceeds
TaskKilled
seconds
Started
Interrupted
allocation
reset
after
not
empty
dir
broadcast
code
ID
Runnable
whose
Assuming
Lost
marked
Reporting
Saved
Stage
register
Cleaned
Exit
WebUI
variable
accumulator
message
when
cleared
Parents
Cancelling
and
loading
to
up
cache
including
Registering
Attempted
Successfully
creating
had
Application
Process
Disabling
Manager
running
Connecting
exceeding
there
retry
may
statuses
computing
reduceId
added
duplicate
interrupted
Got
down
Details
port
id
boosting
overhead
Total
context
cores
towards
removed
send
if
Missing
Space
which
With
count
split
pipe
job
local
Told
heartbeater
aborting
contains
Getting
Found
executors
dropped
Remote
connection
Set
SIGTERM
attempt
Ref
limits
stopped
Algorithm
executorexited
body
Cannot
runJob
ready
unregistered
partition
peer
serialized
Stream
state
input
Exception
retrying
RECEIVED
due
got
sending
Broken
occurred
Dropping
Registered
by
still
as
progress
shuffle
Removing
Data
of
parents
Bus
exception
listening
Remoting
staging
kill
Reading
in
channels
Ignored
Storage
An
Committer
free
Instead
executor
Driver
app
Another
because
map
timestamp
Committed
manager
outputs
locally
disconnected
stop
permissions
Disconnected
response
each
stored
virtual
attempts
version
Info
all
number
requested
datanode
spark
Master
unexpectedly
initial
counting
java
User
Success
Shutdown
driverUrl
one
it
sent
transports
Slf4j
terminated
Finished
error
containers
thread
Doing
or
Attempting
Requesting
Launch
been
Container
intervals
requestId
driver
TaskSet
very
disassociated
cancelled
wrong
recommended
are
Endpoint
List
prior
beginning
run
Resubmitting
address
io
epoch
shut
since
resource
vCores
Map
Security
Putting
launching
Launching
new
use
File
Host
Adding
maxMem
timeout
registered
Job
connect
boot
Starting
final
Already
Netty
token
reason
called
have
user
signal
container
Shutting
Output
Input
Partition
Reporter
larger
ui
max
Fetch
will
Setting
Removed
them
invoking
paths
initialization
Prepared
status
Issue
Spark
Listener
commanded
with
Running
maximum
Pending
lost
no
Local
newly
any
failures
handlers
remove
earlier
Slave
an
Hostname
Not
The
tried
Chunk
authentication
Completed
finish
please
Executor
closed
Asking
total
Python
termination
heartbeat
assigned
modify
visibility
Shuffle
clearing
started
closing
from
deleting
for
Traceback
create
Logger
requests
fetch
master
Final
Context
channel
Add
Abandoning
Tracker
now
SIGNAL
looking
failure
controlled
already
endpoint
textFile
Message
reachable
left
results
inactive
Added
scheme
daemon
while
unused
Result
Invoking
intentionally
YARN
web
From
Marking
communicating
runnable
created
Received
has
failed
unknown
capacity
Uncaught
Task
users
registering
retries
fetching
Consider
Preparing
bytes
Updating
Using
block
exit
Stopped
proceeding
took
flushing
updating
tracker
Reason
size
successfully
its
computed
RPC
done
Still
outstanding
timed
separate
call
Filter
expired
Select
limit
Retrying
Server
list
fails
Excluding
resources
stream
ResultStage
unavailable
trying
curMem
Worker
slave
reading
proxy
missing
at
Will
large
partitions
application
waiting
IOException
host
Deleting
reply
way
completed
a
available
adjust
remote
Free
Store
addresses
launch
such
Error
type
filter
time
blocks
Changing
Connector
millis
locations
Resource
destination
dead
Closed
fetches
so
REPL
task
Size
unrelated
Failure
crashed
Asked
reporter
last
buffer
node
cleaning
maxRetries
SparkUI
estimated
request
row
event
Channel
get
directory
Requested
Backend
RpcResponse
Web
server
told
class
exited
marking
Scheduler
Block
killed
Unregistering
loss
quiet
recent
starting
ensure
Trying
process
scheduling
but
used
on
view
Created
than
output
Opening
disabled
Failed
pool
worker
found
this
Incomplete
times
values
Resubmitted
Times
out
Memory
hook
UI
Attempt
URI
This
reached
service
Submitting
exitCode
dropping
stages
finished
shutdown
is
RAM
Ignoring
remoting
bigger
most
explicit
location
Id
some
set
deprecated
init
Connection
capability
program
the
heartbeats
be
